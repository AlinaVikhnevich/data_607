---
title: "Project 3: Project Proposal"
author: "Group Members: Alina Vikhnevich, Olivia Azevedo, Alyssa Gurkas, Musrat Jahan"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: cerulean
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r chunk-settings, include=FALSE}
# to be updated 
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(tidyverse)
library(stringi)
library(DiagrammeR)
library(dplyr)
library(tidyr)
library(stringr)
```

## Introduction
This project explores what are the most valuable data science skills. To answer
this, the following methodology was followed:

*Data Collection* - import data from sources [insert here] 

*Data Normalization* - [insert sentence about what data cleaning occurred]

*Export to Database* - [insert sentence about where data is hosted]

*Data Analysis* - [insert sentence about the completed data analysis]

*Summary of Findings* - [insert sentence about summarizing findings]

### Research Questions
1. [insert here]
2. [insert here]
3. [insert here]

## Data Sources

-   [Computer and Mathematical Occupations – Profile Data](https://www.bls.gov/oes/current/oes150000.htm) - This data
    source provides detailed information on computer and mathematical
    occupations. In this project, we may use the Bureau of Labor
    Statistics to identify occupational codes related to data science,
    and relevant information such as income.
-   [United Nations Standard Products and Services Code](https://www.undp.org/unspsc) - 
    This data source includes information about products and services and can be
    used to analyze company expenditures.
-   [Projections Central](https://projectionscentral.org/directdownloads) - This data
    source includes projections of industry and occupational employment
    by state and the US. This could be used to explore the projected
    outcome for certain occupations related to data science such as data
    scientists, analysts, data engineers, and data architects.
-   [O\*Net Database](https://www.onetcenter.org/database.html#all-files) – The
    O\*NET database outlines various information that describe work and
    worker characteristics, including skill requirements for many
    occupations. This data source may be used to explore skillsets,
    applications, and programming languages used in occupations related
    to data science.

## Read Data

```{r load-data}
# load the O*NET Skills Dataset, data dictionary available here: 
# https://www.onetcenter.org/dictionary/25.1/excel/knowledge.html
skills = read.csv("https://raw.githubusercontent.com/AlinaVikhnevich/data_607/refs/heads/main/Project%203/Data/Skills.csv")

# load the OES Data [insert info on where data came from]
oes = read.csv("https://raw.githubusercontent.com/AlinaVikhnevich/data_607/refs/heads/main/Project%203/Data/OES_Report_Industries_with_DS_Employment.csv",
                  skip = 6, nrows = 284,
                  header = FALSE)

# load the United Nations Standard Products and Services Code [insert info on where data came from]
soc_ref = read.csv("https://raw.githubusercontent.com/AlinaVikhnevich/data_607/refs/heads/main/Project%203/Data/UNSPSC%20Reference.csv")
```

```{r col-names-soc-ref}
colnames(soc_ref) = c(
                        'commodity_code', 
                        'commodity_title', 
                        'class_code', 
                        'class_title', 
                        'family_code', 
                        'family_title', 
                        'segment_code', 
                        'segment_title')

soc_ref = soc_ref |>
  mutate_all(as.character)

# Alyssa to do: include table in report that will be published (using kable package)
head(soc_ref)
```

```{r col-names-skills}
colnames(skills) = c('class_code', 'class_title', 'element_id', 'element_name', 'scale_id', 'scale_name',
                     'value', 'n', 'se', 'lower_ci', 'upper_ci', 'recommend_suppress', 
                      'not_relevant', 'date', 'domain_source')

skills_df = skills |>
  mutate(class_code = str_replace(str_replace(class_code, '\\.', ''), '-', ''))

# Alyssa to do: include table in report that will be published (using kable package)
head(skills_df)
```

```{r col-names-oes}
colnames(oes) = c('industry', 'employment', 'employment_prct_relative_se',
                             'hr_wage_mean', 'annual_wage_mean', 'wage_prct_relative_se','hr_wage_10_prcentile',
                              'hr_wage_25_prcentile', 'hr_wage_median', 'hr_wage_75_prcentile',
                              'hr_wage_90_prcentile', 'annual_wage_10_prcentile',
                              'annual_wage_25_prcentile', 'annual_wage_median', 'annual_wage_75_prcentile',
                              'annual_wage_90_prcentile')


oes_df = oes |>
  mutate(soc = str_match(industry, "\\s*(\\d{2}-\\d{2,}[A-Z]*\\d*)")[,2]) |>
  mutate(soc = stri_pad_right(str_replace(soc, '-', ''), 8, 0)) |>
  mutate(sector_soc_1 =  str_match(industry, "^Sector(s)*\\s{1}(.*)\\s-.*")[,3]) |>
  mutate(sector_soc_2 = str_match(industry, "\\s*(\\d{2}---\\d{2})")[,2]) |>
  mutate(sector_soc = ifelse(is.na(sector_soc_1), sector_soc_2, sector_soc_1)) |>
  mutate(sector_soc = str_replace(str_replace(str_replace(sector_soc, '---', ', '), 'and', ', '), ', ,', ',')) |>
  mutate(segment_soc = ifelse(is.na(sector_soc), sector_soc, stri_pad_right(sector_soc, 8, 0))) |>
  mutate(industry = gsub( " \\(.*$", "", industry))

oes_df_tidy <- oes_df |> 
  pivot_longer(
    cols = starts_with("hr"), 
    names_to = "hourly wage statistic", 
    values_to = "hourly wage value",
    )

oes_df_tidy <- oes_df_tidy |> 
  pivot_longer(
    cols = starts_with("annual"), 
    names_to = "annual wage statistic", 
    values_to = "annual wage value")

# Alyssa to do: include table in report that will be published (using kable package)
head(oes_df_tidy)
industry_vector <- oes_df$industry
str_view(industry_vector, "Computer")
str_view(industry_vector, "Data")
#unique(industry_vector)
```

**[Insert information about what the code about does, answer how does this makes
the data tidy. Feedback from Professor Kowalchuk: make sure you highlight the structure 
(tidy) of the analysis dataframe in the project submission.]**

## Industry tidy normalized tables

```{r tbls-industry}
family_hr_wage_df = 
  oes_df |>
  dplyr::filter(is.na(segment_soc)) |>
  select(soc, starts_with('hr')) |>
  pivot_longer(
    cols = starts_with('hr'),
    names_to = 'hourly_wage_stat',
    names_prefix = 'hr_wage_',
    values_to = 'dollars'
  ) |>
  mutate(dollars = str_remove(dollars, "^\\$"))  # Removes "$"

family_annual_wage_df = 
  oes_df |>
  dplyr::filter(is.na(segment_soc)) |>
  select(soc, starts_with('annual')) |>
  pivot_longer(
    cols = starts_with('annual'),
    names_to = 'annual_wage_stat',
    names_prefix = 'annual_wage_',
    values_to = 'dollars'
  ) |>
  mutate(dollars = str_remove(dollars, "^\\$"))  # Removes "$"
```

```{r wage-tbls}
segemnt_hr_wage_df = oes_df |>
  drop_na(segment_soc) |>
  select(segment_soc, starts_with('hr')) |>
  pivot_longer(
    cols = starts_with('hr'),
    names_to = 'hr_wage_stat',
    names_prefix = 'hr_wage_',
    values_to = 'dollars'
    ) |>
  mutate(dollars = substr(dollars, 2, length(dollars))) 


segemnt_annual_wage_df = oes_df |>
  drop_na(segment_soc) |>
  select(segment_soc, starts_with('annual')) |>
  pivot_longer(
    cols = starts_with('annual'),
    names_to = 'annual_wage_stat',
    names_prefix = 'annual_wage_',
    values_to = 'dollars'
    ) |>
  mutate(dollars = substr(dollars, 2, length(dollars))) 
```

```{r skills-tbls}
element_ref = 
  skills_df |>
  select(element_id, element_name) |>
  distinct()

im_skills_df = skills_df |>
  dplyr::filter(scale_id == 'IM') |>
  select(class_code, class_title, element_id, value)

level_skills_df = skills_df |>
  dplyr::filter(scale_id == 'LV') |>
  select(class_code, class_title, element_id, value)
```

### Data Processing and Normalization
**[Insert information here about the data processing and normalization process.
Explain what makes the data tidy, and how it will be used to answer our 
research questions.]**

### MySQL Database
**[insert 1-2 sentences here about where data is stored, how the MySQL database 
is structured, and how it was configured.]**

#### Database Connection

```{r establish-connection}
# this is where we should establish the connection to the database

```

### Data Cleaning

```{r data-analysis}
# this is where we should analyze the data so that it can be visualized
```

### Data Analysis and Visualization

#### Question 1: Which skills are considered the most important in the data science field?

#### Question 2: What are the

#### Question 3: [insert here]

### Summary of Findings
[insert conclusion paragraph here].
