---
title: "Project 3: Project Proposal"
author: "Group Members: Alina Vikhnevich, Olivia Azevedo, Alyssa Gurkas, Musrat Jahan"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: cerulean
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r chunk-settings, include=FALSE}
# to be updated 
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(tidyverse)
library(stringi)
library(DiagrammeR)
library(dplyr)
library(tidyr)
library(stringr)
library(jsonlite)
```

## Introduction
This project explores what are the most valuable data science skills. To answer
this, the following methodology was followed:

*Data Collection* - import data from Bureau of Labor Statistics, United Nations
Standard Products and Services Code, Projections Central, and O*Net (data sources
are listed below). 

*Data Normalization* - clean and normalize the data by (1) removing unnecessary 
strings in the skills data frame so that the values are uniform within the 
`class_code` column, (2) replacing and matching strings within the OES Data 
through regex patterns, (3) and pivot the OES dataset wider, and then longer,
so that every row in the dataset is an observation (4) develop an hourly wage 
table by selecting values from the `soc` column that start with 'hr'. Then, 
remove NAs from the wage dataset, and pivot the data longer, and remove 
characters so that it numeric values be analyzed (5) develop an annual wage
table by selecting values from the `soc` column that start with 'annual' and then
follow a similar cleaning process in the step four (6) develop a segment wage
table by selecting values from the `soc` column that start with 'annual' and then
follow a similar cleaning process in the step four.

*Export to Database* - [insert sentence about where data is stored]

*Data Analysis* - [insert sentence about the completed data analysis]

*Summary of Findings* - [insert sentence about summarizing findings]

### Research Questions
1. Which skills are considered the most important in the data science field?
2. What is the relationship between skill importance and job compensation? How does this vary across industries?
3. ***What is relationship between projected employment and the importance of job skills?***

## Data Sources

-   [Computer and Mathematical Occupations – Profile Data](https://www.bls.gov/oes/current/oes150000.htm) - This data        source provides detailed information on computer and mathematical
    occupations. In this project, we may use the Bureau of Labor
    Statistics to identify occupational codes related to data science,
    and relevant information such as income.
-   [United Nations Standard Products and Services Code](https://www.undp.org/unspsc) - 
    This data source includes information about products and services and can be
    used to analyze company expenditures.
-   [Projections Central](https://projectionscentral.org/directdownloads) - This data
    source includes projections of industry and occupational employment
    by state and the US. This could be used to explore the projected
    outcome for certain occupations related to data science such as data
    scientists, analysts, data engineers, and data architects.
-   [O\*Net Database](https://www.onetcenter.org/database.html#all-files) – The
    O\*NET database outlines various information that describe work and
    worker characteristics, including skill requirements for many
    occupations. This data source may be used to explore skillsets,
    applications, and programming languages used in occupations related
    to data science.

## Read Data
**NOTE FOR GROUP: Can someone help identify where the link to the downloads for
OES and SOC came from? I am having a hard time finding it -Alyssa**
```{r load-data}
# load the O*NET Skills Dataset, data dictionary available here: 
# https://www.onetcenter.org/dictionary/25.1/excel/knowledge.html
skills <- read.csv("https://raw.githubusercontent.com/AlinaVikhnevich/data_607/refs/heads/main/Project%203/Data/Skills.csv")

# load the OES Data option to create custom table, then input data science and returned all related industries 
oes <- read.csv("https://raw.githubusercontent.com/AlinaVikhnevich/data_607/refs/heads/main/Project%203/Data/OES_Report_Industries_with_DS_Employment.csv",
                  skip = 6, nrows = 284,
                  header = FALSE)

# load the United Nations Standard Products and Services Code - reference file for occupational codes in:
soc_ref <- read.csv("https://raw.githubusercontent.com/AlinaVikhnevich/data_607/refs/heads/main/Project%203/Data/UNSPSC%20Reference.csv")

# load the projected long-term employment from Projections Central (https://projectionscentral.org/directdownloads) **this is only if we decide to include projections
proj <- fromJSON("https://public.projectionscentral.org/Projections/LongTermRestJson")
proj <- as.data.frame(proj)
```

```{r col-names-soc-ref}
colnames(soc_ref) <- c(
                        'commodity_code', 
                        'commodity_title', 
                        'class_code', 
                        'class_title', 
                        'family_code', 
                        'family_title', 
                        'segment_code', 
                        'segment_title')

soc_ref <- soc_ref |>
  mutate_all(as.character)

# Alyssa to do: include table in report that will be published (using kable package)
head(soc_ref)
```

```{r col-names-skills}
colnames(skills) = c('class_code', 'class_title', 'element_id', 'element_name', 'scale_id', 'scale_name',
                     'value', 'n', 'se', 'lower_ci', 'upper_ci', 'recommend_suppress', 
                      'not_relevant', 'date', 'domain_source')

skills_df = skills |>
  mutate(class_code = str_replace(str_replace(class_code, '\\.', ''), '-', ''))

# Alyssa to do: include table in report that will be published (using kable package)
head(skills_df)
```

```{r col-names-oes}
colnames(oes) = c('industry', 'employment', 'employment_prct_relative_se',
                             'hr_wage_mean', 'annual_wage_mean', 'wage_prct_relative_se','hr_wage_10_prcentile',
                              'hr_wage_25_prcentile', 'hr_wage_median', 'hr_wage_75_prcentile',
                              'hr_wage_90_prcentile', 'annual_wage_10_prcentile',
                              'annual_wage_25_prcentile', 'annual_wage_median', 'annual_wage_75_prcentile',
                              'annual_wage_90_prcentile')


oes_df = oes |>
  mutate(soc = str_match(industry, "\\s*(\\d{2}-\\d{2,}[A-Z]*\\d*)")[,2]) |>
  mutate(soc = stri_pad_right(str_replace(soc, '-', ''), 8, 0)) |>
  mutate(sector_soc_1 =  str_match(industry, "^Sector(s)*\\s{1}(.*)\\s-.*")[,3]) |>
  mutate(sector_soc_2 = str_match(industry, "\\s*(\\d{2}---\\d{2})")[,2]) |>
  mutate(sector_soc = ifelse(is.na(sector_soc_1), sector_soc_2, sector_soc_1)) |>
  mutate(sector_soc = str_replace(str_replace(str_replace(sector_soc, '---', ', '), 'and', ', '), ', ,', ',')) |>
  mutate(segment_soc = ifelse(is.na(sector_soc), sector_soc, stri_pad_right(sector_soc, 8, 0))) |>
  mutate(industry = gsub( " \\(.*$", "", industry))

oes_df_tidy <- oes_df |> 
  pivot_longer(
    cols = starts_with("hr"), 
    names_to = "hourly wage statistic", 
    values_to = "hourly wage value",
    )

oes_df_tidy <- oes_df_tidy |> 
  pivot_longer(
    cols = starts_with("annual"), 
    names_to = "annual wage statistic", 
    values_to = "annual wage value")

# Alyssa to do: include table in report that will be published (using kable package)
head(oes_df_tidy)
industry_vector <- oes_df$industry
str_view(industry_vector, "Computer")
str_view(industry_vector, "Data")
#unique(industry_vector)
```

**[Insert information about what the code about does, answer how does this makes
the data tidy. Feedback from Professor Kowalchuk: make sure you highlight the structure 
(tidy) of the analysis dataframe in the project submission.]**

## Industry tidy normalized tables

```{r tbls-industry}
family_hr_wage_df <- 
  oes_df |>
  dplyr::filter(is.na(segment_soc)) |>
  select(soc, starts_with('hr')) |>
  pivot_longer(
    cols = starts_with('hr'),
    names_to = 'hourly_wage_stat',
    names_prefix = 'hr_wage_',
    values_to = 'dollars'
  ) |>
  mutate(dollars = str_remove(dollars, "^\\$"))  # Removes "$"

family_annual_wage_df <- 
  oes_df |>
  dplyr::filter(is.na(segment_soc)) |>
  select(soc, starts_with('annual')) |>
  pivot_longer(
    cols = starts_with('annual'),
    names_to = 'annual_wage_stat',
    names_prefix = 'annual_wage_',
    values_to = 'dollars'
  ) |>
  mutate(dollars = str_remove(dollars, "^\\$"))  # Removes "$"
```

```{r wage-tbls}
segemnt_hr_wage_df <- oes_df |>
  drop_na(segment_soc) |>
  select(segment_soc, starts_with('hr')) |>
  pivot_longer(
    cols = starts_with('hr'),
    names_to = 'hr_wage_stat',
    names_prefix = 'hr_wage_',
    values_to = 'dollars'
    ) |>
  mutate(dollars = substr(dollars, 2, length(dollars))) 


segemnt_annual_wage_df <- oes_df |>
  drop_na(segment_soc) |>
  select(segment_soc, starts_with('annual')) |>
  pivot_longer(
    cols = starts_with('annual'),
    names_to = 'annual_wage_stat',
    names_prefix = 'annual_wage_',
    values_to = 'dollars'
    ) |>
  mutate(dollars = substr(dollars, 2, length(dollars))) 
```

```{r skills-tbls}
element_ref <- 
  skills_df |>
  select(element_id, element_name) |>
  distinct()

im_skills_df <- skills_df |>
  dplyr::filter(scale_id == 'IM') |>
  select(class_code, class_title, element_id, value)

level_skills_df <- skills_df |>
  dplyr::filter(scale_id == 'LV') |>
  select(class_code, class_title, element_id, value)
```

### Data Processing and Normalization
**[Insert information here about the data processing and normalization process.
Explain what makes the data tidy, and how it will be used to answer our 
research questions.]**

### MySQL Database
**[insert 1-2 sentences here about where data is stored, how the MySQL database 
is structured, and how it was configured.]**

#### Database Connection

```{r establish-connection}
# this is where we should establish the connection to the database

```

### Data Cleaning

```{r data-analysis}
# this is where we should analyze the data so that it can be visualized
```

### Data Analysis and Visualization

#### Question 1: Which skills are considered the most important in the data science field?

#### Question 2: What is the relationship between skill importance and job compensation? How does this vary across industries?

#### Question 3: What is relationship between projected employment and the importance of job skills?

### Summary of Findings
[insert conclusion paragraph here].
